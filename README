Weighted Rank-Based Scoring
---------------------------
Ronald L. Rivest
1/28/16
 
We describe and implement a simple method to rank students in a class,
based on their performance on each grade component (homework, etc.)

The main question we deal with is:

    ``How should one normalize grades for different components, so
      that they are on a `common scale', before we combine them
      using a weighted averaging method?''

The answer we provide is ``rank-based'':
 
     If there are n students who have completed a given component,
     then they receive rank-based scores on that component of

         1/(n+1),  2/(n+1),  3/(n+1), ..., n/(n+1)

     with the best student receiving the highest score.

     That is, assuming their grades are distinct.  Students with
     tied grades receive the same score, which is the average of
     what they would have received if different scores were required.

     Example:  Four students with grades on quiz #1 of

               A      B     C     D

               receive rank-based scores of:

               4/5    3/5   2/5   1/5

     Example:  The same four students with grades on quiz #2 of

               A      --    C     C

               (here B missed the quiz) receive rank-based scores of:

               3/4    --    1.5/4   1.5/4

     Example:  If the quizzes are weighted equally, then the
               students receive overall scores that is the average
               of the scores received on the components they did:

               31/40  24/40 15.5/40 6.5/40

               (Of course, one might use a different policy for handling
               missed components.)
 
We call this method "weighted rank-based scoring", since 
   -- a score for each student is computed as a weighted average
      of that student's score on each component, and 
   -- a student's score on a component is based on the student's rank
      among all students who completed that component.
Our implementation also provide support allowing students to drop components
(for example, dropping their lowest two homework grades).

To illustrate, we provide a python3 program (rank.py) that takes an input CSV
file representing data like the following for a class of five students,
with a student ID, four homeworks, two quizzes, and a final exam:

      STU_ID   H1  H2   H3   H4    Q1   Q2  Final
          0     5   5    5    5    20   20     30

        X94     9   9    9   --   100   92    200
        X87     8   9    6   10    84   94    200
        X99    --   9   10    8    --   87    200
        X78     6   8    7    8    52   56    160
        X63     3   5   --    2    63   61    143
         
giving a header line, component weights, and student grades
per component (with possible missing values), and produces
a rank-ordered student listing like this:

    LISTING OF ALL STUDENTS (BEST FIRST) WITH SCALED SCORES:
      STU_ID      H1      H2      H3      H4      Q1      Q2   Final  wtd_score  rank 
        X94    0.800   0.667   0.600      --   0.800   0.667   0.667      0.702     1 
        X87    0.600   0.667   0.200   0.800   0.600   0.833   0.667      0.667     2 
        X99       --   0.667   0.800   0.500      --   0.500   0.667      0.613     3 
        X78    0.400   0.333   0.400   0.500   0.200   0.167   0.333      0.283     4 
        X63    0.200   0.167      --   0.200   0.400   0.333   0.167      0.265     5 

Here each grade is converted to a rank-based score, and the (weighted)
scores are averaged for each student.  The students are then sorted
into decreasing order by weighted ranked-base score; the last column
("rank") gives the student's rank in the class.

The program also enables following a policy of dropping lowest components
in a category.  For example:

    Effecting the following drop policy:
        Dropping lowest 2 from: H1 H2 H3 H4
        Dropping lowest 1 from: Q1 Q2
    Recomputing weighted scores and ranks...
    --------------------------------------------------------------------------------
     LISTING OF ALL STUDENTS (BEST FIRST) WITH SCALED AND DROPPED SCORES:
      STU_ID      H1      H2      H3      H4      Q1      Q2   Final  wtd_score  rank 
        X87       --   0.667      --   0.800      --   0.833   0.667      0.733     1 
        X94    0.800   0.667      --      --   0.800      --   0.667      0.722     2 
        X99       --   0.667   0.800      --      --   0.500   0.667      0.622     3 
        X78       --      --   0.400   0.500   0.200      --   0.333      0.308     4 
        X63    0.200      --      --   0.200   0.400      --   0.167      0.250     5 

The method used here works as follows:

  (1) For each component (e.g. each homework, quiz), compute a "raw scorek"
      for each student, from 1 (for worst) to m (for best) (if there are
      m students with grades on that component).

      If several students would be tied, then they all receive the
      same average rank.  For example, if nine students have grades
              100   100   100    92    92    85    85    85    46
      then they receive respective raw scores:
                8     8     8   6.5   6.5     4     4     4     1
      This is known as handling ties by "fractional ranking"; see
          https://en.wikipedia.org/wiki/Ranking#Ranking_in_statistics

      Missing grades are ignored here; they just reduce the number m.

  (2) These raw scores are scaled to the interval [0,1] by dividing
      by (m+1), where m is the number of students having a grade for
      that component.  In the above example, the scaled scores
      scores) are:
              0.8   0.8   0.8  0.65  0.65   0.4   0.4   0.4   0.1
      If all ranks are distinct, then the scaled ranks are:
             1/(m+1)   2/(m+1)   3/(m+1)  ...   m/(m+1)

  (3) The weighted average score is then computed for each student, and
      the students are sorted into order of decreasing score.

      Since some scores may be missing, the relevant weights for that
      student are normalized to sum to 1 before the weighted sum is
      computed.

See the included files for more documentation, code, etc.:

    README                -- this file
    USAGE-NOTES.txt       -- discussion on how to use rank.py

    rank.py               -- main program
    make_data.py          -- generates test CSV files
    policy.py             -- if you want to e.g. drop lowest homework scores

    testnnnn.csv                        -- input CSV test data file with nnnn students

    testnnnn.csv.1.grades.rank.csv        -- corresponding output CSV file with grades and
                                             new rank
    testnnnn.csv.2.scores.rank.csv        -- same, except grades replaced with scaled scores
                                             per component
    testnnnn.csv.3.droppedscores.rank.csv -- same as previous, but with some scores dropped by
                                             policy.py, and ranks recomputed

    (Some of the test data is in the subfolder "examples".)

Discussion:

-- An earlier version was based on the use of Kemeny-Young score rankings.
   While this was technically interesting, it had a number of deficiencies,
   including complexity.  See the subdirectory this github repository named
      old-alternative-kemeny-based-method
   if you are interested in this. The current method bears a closer relation
   to the "Borda count" method of voting than to the Kemeny-Young method.  

-- I think the best approach for dealing with exceptions, etc. is
   to drop the lowest scores for homeworks, etc.  This policy is
   class-specific, and so isn't implemented here.  But it should
   presumably be done after the scaled ranks are computed, but
   before the weighted sums are computed.  A typical policy might
   be to drop the two lowest homework grades and the lowest quiz
   grade.  Such a policy provides motivation for the student to do
   as many of the assignment as they can, since it is unpredictable
   to them as to which ones they will get the best ranking on.
   (And note that getting a perfect score on homework #1 can still
   be bested by a non-perfect score on homework #2, due to effects
   of missing grades, ties, etc.)  For example, if four students
   all have perfect 10 scores on problem set #1, then their scaled
   ranks are all 0.500.  If the same four students get distinct
   scores on problem set #2, then the scaled scores are:
                0.2  0.4  0.6  0.8
   so even the number 2 student (with scaled score 0.6) is doing better
   here than on problem set #1.

   The module policy.py allows for implementation of policies to
   drop e.g. the lowest one or two homework grades, the lowest quiz
   grade, etc.  This file should be modified to get the desired policy.

-- Because the final score is just a weighted sum, the question as
   to "what grade do I need to get on the final in order to get a B 
   for this course" is potentially answerable, if the B/C cutoff point
   is known already.  The answer, however, is in terms of scaled score...
   I'm not much in favor of this sort of a dialogue, but some may find
   it helpful...

-- The following commercial grading systems are worth checking out, as
   well:

       www.gradesource.com  -- emphasizes record-keeping and grade aggregation
                               which is done by weighted sum of point scores
              
       www.gradescope.com   -- allow students to upload homeworks, and have
                               graders grade them online, according to a
                               rubric that may evolve

-- Thanks to Marina Meila, Mihir Bellare, Srini Devadas, Shalev Ben-David, and
   Anak Yodpinyanee for helpful discussions and feedback.

Ron Rivest  
2016-01-28
